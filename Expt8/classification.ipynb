{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('weatherAUS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre - Processing of the dataset is needed to be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('NA', pd.NA, inplace=True)\n",
    "df.replace('nan', pd.NA, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of               Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  \\\n",
      "0       2008-12-01   Albury     13.4     22.9       0.6          NaN   \n",
      "1       2008-12-02   Albury      7.4     25.1       0.0          NaN   \n",
      "2       2008-12-03   Albury     12.9     25.7       0.0          NaN   \n",
      "3       2008-12-04   Albury      9.2     28.0       0.0          NaN   \n",
      "4       2008-12-05   Albury     17.5     32.3       1.0          NaN   \n",
      "...            ...      ...      ...      ...       ...          ...   \n",
      "145455  2017-06-21    Uluru      2.8     23.4       0.0          NaN   \n",
      "145456  2017-06-22    Uluru      3.6     25.3       0.0          NaN   \n",
      "145457  2017-06-23    Uluru      5.4     26.9       0.0          NaN   \n",
      "145458  2017-06-24    Uluru      7.8     27.0       0.0          NaN   \n",
      "145459  2017-06-25    Uluru     14.9      NaN       0.0          NaN   \n",
      "\n",
      "        Sunshine WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  \\\n",
      "0            NaN           W           44.0          W  ...        71.0   \n",
      "1            NaN         WNW           44.0        NNW  ...        44.0   \n",
      "2            NaN         WSW           46.0          W  ...        38.0   \n",
      "3            NaN          NE           24.0         SE  ...        45.0   \n",
      "4            NaN           W           41.0        ENE  ...        82.0   \n",
      "...          ...         ...            ...        ...  ...         ...   \n",
      "145455       NaN           E           31.0         SE  ...        51.0   \n",
      "145456       NaN         NNW           22.0         SE  ...        56.0   \n",
      "145457       NaN           N           37.0         SE  ...        53.0   \n",
      "145458       NaN          SE           28.0        SSE  ...        51.0   \n",
      "145459       NaN         NaN            NaN        ESE  ...        62.0   \n",
      "\n",
      "        Humidity3pm  Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  \\\n",
      "0              22.0       1007.7       1007.1       8.0       NaN     16.9   \n",
      "1              25.0       1010.6       1007.8       NaN       NaN     17.2   \n",
      "2              30.0       1007.6       1008.7       NaN       2.0     21.0   \n",
      "3              16.0       1017.6       1012.8       NaN       NaN     18.1   \n",
      "4              33.0       1010.8       1006.0       7.0       8.0     17.8   \n",
      "...             ...          ...          ...       ...       ...      ...   \n",
      "145455         24.0       1024.6       1020.3       NaN       NaN     10.1   \n",
      "145456         21.0       1023.5       1019.1       NaN       NaN     10.9   \n",
      "145457         24.0       1021.0       1016.8       NaN       NaN     12.5   \n",
      "145458         24.0       1019.4       1016.5       3.0       2.0     15.1   \n",
      "145459         36.0       1020.2       1017.9       8.0       8.0     15.0   \n",
      "\n",
      "        Temp3pm  RainToday  RainTomorrow  \n",
      "0          21.8         No            No  \n",
      "1          24.3         No            No  \n",
      "2          23.2         No            No  \n",
      "3          26.5         No            No  \n",
      "4          29.7         No            No  \n",
      "...         ...        ...           ...  \n",
      "145455     22.4         No            No  \n",
      "145456     24.5         No            No  \n",
      "145457     26.1         No            No  \n",
      "145458     26.0         No            No  \n",
      "145459     20.9         No           NaN  \n",
      "\n",
      "[145460 rows x 23 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Initial view of the dataset\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of        Location  MinTemp  MaxTemp  Rainfall WindGustDir  WindGustSpeed  \\\n",
      "0        Albury     13.4     22.9       0.6           W           44.0   \n",
      "1        Albury      7.4     25.1       0.0         WNW           44.0   \n",
      "2        Albury     12.9     25.7       0.0         WSW           46.0   \n",
      "3        Albury      9.2     28.0       0.0          NE           24.0   \n",
      "4        Albury     17.5     32.3       1.0           W           41.0   \n",
      "...         ...      ...      ...       ...         ...            ...   \n",
      "145454    Uluru      3.5     21.8       0.0           E           31.0   \n",
      "145455    Uluru      2.8     23.4       0.0           E           31.0   \n",
      "145456    Uluru      3.6     25.3       0.0         NNW           22.0   \n",
      "145457    Uluru      5.4     26.9       0.0           N           37.0   \n",
      "145458    Uluru      7.8     27.0       0.0          SE           28.0   \n",
      "\n",
      "       WindDir9am WindDir3pm  WindSpeed9am  WindSpeed3pm  Humidity9am  \\\n",
      "0               W        WNW          20.0          24.0         71.0   \n",
      "1             NNW        WSW           4.0          22.0         44.0   \n",
      "2               W        WSW          19.0          26.0         38.0   \n",
      "3              SE          E          11.0           9.0         45.0   \n",
      "4             ENE         NW           7.0          20.0         82.0   \n",
      "...           ...        ...           ...           ...          ...   \n",
      "145454        ESE          E          15.0          13.0         59.0   \n",
      "145455         SE        ENE          13.0          11.0         51.0   \n",
      "145456         SE          N          13.0           9.0         56.0   \n",
      "145457         SE        WNW           9.0           9.0         53.0   \n",
      "145458        SSE          N          13.0           7.0         51.0   \n",
      "\n",
      "        Humidity3pm  Pressure9am  Pressure3pm  Temp9am  Temp3pm RainToday  \\\n",
      "0              22.0       1007.7       1007.1     16.9     21.8        No   \n",
      "1              25.0       1010.6       1007.8     17.2     24.3        No   \n",
      "2              30.0       1007.6       1008.7     21.0     23.2        No   \n",
      "3              16.0       1017.6       1012.8     18.1     26.5        No   \n",
      "4              33.0       1010.8       1006.0     17.8     29.7        No   \n",
      "...             ...          ...          ...      ...      ...       ...   \n",
      "145454         27.0       1024.7       1021.2      9.4     20.9        No   \n",
      "145455         24.0       1024.6       1020.3     10.1     22.4        No   \n",
      "145456         21.0       1023.5       1019.1     10.9     24.5        No   \n",
      "145457         24.0       1021.0       1016.8     12.5     26.1        No   \n",
      "145458         24.0       1019.4       1016.5     15.1     26.0        No   \n",
      "\n",
      "       RainTomorrow  \n",
      "0                No  \n",
      "1                No  \n",
      "2                No  \n",
      "3                No  \n",
      "4                No  \n",
      "...             ...  \n",
      "145454           No  \n",
      "145455           No  \n",
      "145456           No  \n",
      "145457           No  \n",
      "145458           No  \n",
      "\n",
      "[112925 rows x 18 columns]>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# List of columns to drop from the DataFrame\n",
    "columns_to_drop = ['Evaporation', 'Sunshine', 'Cloud9am', 'Cloud3pm', 'Date']\n",
    "\n",
    "# Drop specified columns from the DataFrame\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Drop rows where any remaining columns have null values\n",
    "df = df.dropna()\n",
    "print(df.head)\n",
    "\n",
    "# List of columns to encode using LabelEncoder\n",
    "columns_to_encode = ['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']\n",
    "\n",
    "# Initialize LabelEncoder and encode each column in columns_to_encode list\n",
    "for column in columns_to_encode:\n",
    "    le = LabelEncoder()\n",
    "    df[column] = le.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of         Location  MinTemp  MaxTemp  Rainfall  WindGustDir  WindGustSpeed  \\\n",
      "0              1     13.4     22.9       0.6           13           44.0   \n",
      "1              1      7.4     25.1       0.0           14           44.0   \n",
      "2              1     12.9     25.7       0.0           15           46.0   \n",
      "3              1      9.2     28.0       0.0            4           24.0   \n",
      "4              1     17.5     32.3       1.0           13           41.0   \n",
      "...          ...      ...      ...       ...          ...            ...   \n",
      "145454        36      3.5     21.8       0.0            0           31.0   \n",
      "145455        36      2.8     23.4       0.0            0           31.0   \n",
      "145456        36      3.6     25.3       0.0            6           22.0   \n",
      "145457        36      5.4     26.9       0.0            3           37.0   \n",
      "145458        36      7.8     27.0       0.0            9           28.0   \n",
      "\n",
      "        WindDir9am  WindDir3pm  WindSpeed9am  WindSpeed3pm  Humidity9am  \\\n",
      "0               13          14          20.0          24.0         71.0   \n",
      "1                6          15           4.0          22.0         44.0   \n",
      "2               13          15          19.0          26.0         38.0   \n",
      "3                9           0          11.0           9.0         45.0   \n",
      "4                1           7           7.0          20.0         82.0   \n",
      "...            ...         ...           ...           ...          ...   \n",
      "145454           2           0          15.0          13.0         59.0   \n",
      "145455           9           1          13.0          11.0         51.0   \n",
      "145456           9           3          13.0           9.0         56.0   \n",
      "145457           9          14           9.0           9.0         53.0   \n",
      "145458          10           3          13.0           7.0         51.0   \n",
      "\n",
      "        Humidity3pm  Pressure9am  Pressure3pm  Temp9am  Temp3pm  RainToday  \\\n",
      "0              22.0       1007.7       1007.1     16.9     21.8          0   \n",
      "1              25.0       1010.6       1007.8     17.2     24.3          0   \n",
      "2              30.0       1007.6       1008.7     21.0     23.2          0   \n",
      "3              16.0       1017.6       1012.8     18.1     26.5          0   \n",
      "4              33.0       1010.8       1006.0     17.8     29.7          0   \n",
      "...             ...          ...          ...      ...      ...        ...   \n",
      "145454         27.0       1024.7       1021.2      9.4     20.9          0   \n",
      "145455         24.0       1024.6       1020.3     10.1     22.4          0   \n",
      "145456         21.0       1023.5       1019.1     10.9     24.5          0   \n",
      "145457         24.0       1021.0       1016.8     12.5     26.1          0   \n",
      "145458         24.0       1019.4       1016.5     15.1     26.0          0   \n",
      "\n",
      "        RainTomorrow  \n",
      "0                  0  \n",
      "1                  0  \n",
      "2                  0  \n",
      "3                  0  \n",
      "4                  0  \n",
      "...              ...  \n",
      "145454             0  \n",
      "145455             0  \n",
      "145456             0  \n",
      "145457             0  \n",
      "145458             0  \n",
      "\n",
      "[112925 rows x 18 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Dataset after dropping columns and removing rows with NaN cells\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical features for outlier detection\n",
    "numerical_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Calculate quartiles and IQR\n",
    "Q1 = df[numerical_features].quantile(0.25)\n",
    "Q3 = df[numerical_features].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Detect outliers using IQR\n",
    "outliers = ((df[numerical_features] < (Q1 - 1.5 * IQR)) | (df[numerical_features] > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "# Remove outliers\n",
    "df_cleaned = df[~outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the pre-processed DataFrame to a CSV file\n",
    "df.to_csv('modified_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-Processing of the dataset is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-processed dataset\n",
    "df = pd.read_csv('modified_dataset.csv')\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df.drop(columns=['RainTomorrow'])\n",
    "y = df['RainTomorrow']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we do for `Linear models: Logistic Regression, Naïve Bayes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before tuning hyperparameters:\n",
      "Linear Model: Logistic Regression\n",
      "Training Accuracy: 0.8496347133052912\n",
      "Testing Accuracy: 0.8475536860748284\n",
      "\n",
      "Naïve Bayes Classifier\n",
      "Training Accuracy: 0.8119216294000443\n",
      "Testing Accuracy: 0.8093867611246403\n",
      "\n",
      "After tuning hyperparameters:\n",
      "Linear Model: Logistic Regression (Tuned)\n",
      "Training Accuracy: 0.849623644011512\n",
      "Testing Accuracy: 0.8475536860748284\n"
     ]
    }
   ],
   "source": [
    "# Before tuning the hyperparameters\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training set, transform the testing set\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "logistic_model = LogisticRegression(max_iter=2000, solver='liblinear')\n",
    "\n",
    "# Fit Logistic Regression model\n",
    "logistic_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate Logistic Regression model\n",
    "logistic_train_accuracy = logistic_model.score(X_train_scaled, y_train)\n",
    "logistic_test_accuracy = logistic_model.score(X_test_scaled, y_test)\n",
    "\n",
    "# Initialize Naïve Bayes model\n",
    "naive_bayes_model = GaussianNB()\n",
    "\n",
    "# Fit Naïve Bayes model\n",
    "naive_bayes_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate Naïve Bayes model\n",
    "naive_bayes_train_accuracy = naive_bayes_model.score(X_train_scaled, y_train)\n",
    "naive_bayes_test_accuracy = naive_bayes_model.score(X_test_scaled, y_test)\n",
    "\n",
    "# Print results\n",
    "print(\"Before tuning hyperparameters:\")\n",
    "print(\"Linear Model: Logistic Regression\")\n",
    "print(\"Training Accuracy:\", logistic_train_accuracy)\n",
    "print(\"Testing Accuracy:\", logistic_test_accuracy)\n",
    "\n",
    "print(\"\\nNaïve Bayes Classifier\")\n",
    "print(\"Training Accuracy:\", naive_bayes_train_accuracy)\n",
    "print(\"Testing Accuracy:\", naive_bayes_test_accuracy)\n",
    "\n",
    "\n",
    "# After tuning the hyperparameters\n",
    "\n",
    "# Initialize Logistic Regression model with tuned hyperparameters\n",
    "logistic_model_tuned = LogisticRegression(max_iter=1000, solver='lbfgs', C=1.0)\n",
    "\n",
    "# Fit Logistic Regression model with tuned hyperparameters\n",
    "logistic_model_tuned.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate Logistic Regression model with tuned hyperparameters\n",
    "logistic_train_accuracy_tuned = logistic_model_tuned.score(X_train_scaled, y_train)\n",
    "logistic_test_accuracy_tuned = logistic_model_tuned.score(X_test_scaled, y_test)\n",
    "\n",
    "# Print results after tuning\n",
    "print(\"\\nAfter tuning hyperparameters:\")\n",
    "print(\"Linear Model: Logistic Regression (Tuned)\")\n",
    "print(\"Training Accuracy:\", logistic_train_accuracy_tuned)\n",
    "print(\"Testing Accuracy:\", logistic_test_accuracy_tuned)\n",
    "\n",
    "# Gaussian Naïve Bayes typically doesn't require tuning hyperparameters,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we do for `Non Linear models: Decision tress, Neural Network`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier:\n",
      "Before tuning hyperparameters:\n",
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.7880008855435023\n",
      "\n",
      "After tuning hyperparameters:\n",
      "Training Accuracy: 0.8707106486606154\n",
      "Testing Accuracy: 0.8437458490148328\n",
      "\n",
      "Neural Network Classifier:\n",
      "Before tuning hyperparameters:\n",
      "Training Accuracy: 0.8678326322780606\n",
      "Testing Accuracy: 0.8574717733008634\n",
      "\n",
      "After tuning hyperparameters:\n",
      "Training Accuracy: 0.8636373699357981\n",
      "Testing Accuracy: 0.8580916537524906\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training set, transform the testing set\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize Decision Tree model\n",
    "decision_tree_model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# Fit Decision Tree model\n",
    "decision_tree_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate Decision Tree model before tuning\n",
    "decision_tree_train_accuracy_before = decision_tree_model.score(X_train_scaled, y_train)\n",
    "decision_tree_test_accuracy_before = decision_tree_model.score(X_test_scaled, y_test)\n",
    "\n",
    "# Define a smaller search space for Decision Tree hyperparameters\n",
    "param_grid_decision_tree = {'max_depth': [None, 10, 20]}\n",
    "\n",
    "# Use RandomizedSearchCV for hyperparameter tuning\n",
    "random_search_decision_tree = RandomizedSearchCV(DecisionTreeClassifier(random_state=0),\n",
    "                                                param_distributions=param_grid_decision_tree,\n",
    "                                                n_iter=3, cv=3, random_state=0)\n",
    "random_search_decision_tree.fit(X_train_scaled, y_train)\n",
    "decision_tree_model_tuned = random_search_decision_tree.best_estimator_\n",
    "\n",
    "# Evaluate Decision Tree model after tuning\n",
    "decision_tree_train_accuracy_after = decision_tree_model_tuned.score(X_train_scaled, y_train)\n",
    "decision_tree_test_accuracy_after = decision_tree_model_tuned.score(X_test_scaled, y_test)\n",
    "\n",
    "# Initialize Neural Network model\n",
    "neural_network_model = MLPClassifier(random_state=0)\n",
    "\n",
    "# Fit Neural Network model\n",
    "neural_network_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate Neural Network model before tuning\n",
    "neural_network_train_accuracy_before = neural_network_model.score(X_train_scaled, y_train)\n",
    "neural_network_test_accuracy_before = neural_network_model.score(X_test_scaled, y_test)\n",
    "\n",
    "# Define a smaller search space for Neural Network hyperparameters\n",
    "param_grid_neural_network = {'hidden_layer_sizes': [(50,), (100,)]}\n",
    "\n",
    "# Use RandomizedSearchCV for hyperparameter tuning\n",
    "random_search_neural_network = RandomizedSearchCV(MLPClassifier(random_state=0),\n",
    "                                                  param_distributions=param_grid_neural_network,\n",
    "                                                  n_iter=2, cv=3, random_state=0)\n",
    "random_search_neural_network.fit(X_train_scaled, y_train)\n",
    "neural_network_model_tuned = random_search_neural_network.best_estimator_\n",
    "\n",
    "# Evaluate Neural Network model after tuning\n",
    "neural_network_train_accuracy_after = neural_network_model_tuned.score(X_train_scaled, y_train)\n",
    "neural_network_test_accuracy_after = neural_network_model_tuned.score(X_test_scaled, y_test)\n",
    "\n",
    "# Print results\n",
    "print(\"Decision Tree Classifier:\")\n",
    "print(\"Before tuning hyperparameters:\")\n",
    "print(\"Training Accuracy:\", decision_tree_train_accuracy_before)\n",
    "print(\"Testing Accuracy:\", decision_tree_test_accuracy_before)\n",
    "print(\"\\nAfter tuning hyperparameters:\")\n",
    "print(\"Training Accuracy:\", decision_tree_train_accuracy_after)\n",
    "print(\"Testing Accuracy:\", decision_tree_test_accuracy_after)\n",
    "\n",
    "print(\"\\nNeural Network Classifier:\")\n",
    "print(\"Before tuning hyperparameters:\")\n",
    "print(\"Training Accuracy:\", neural_network_train_accuracy_before)\n",
    "print(\"Testing Accuracy:\", neural_network_test_accuracy_before)\n",
    "print(\"\\nAfter tuning hyperparameters:\")\n",
    "print(\"Training Accuracy:\", neural_network_train_accuracy_after)\n",
    "print(\"Testing Accuracy:\", neural_network_test_accuracy_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we do for `Hybrid models: SVM, Bayesian Network`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import HillClimbSearch, BayesianEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"modified_dataset.csv\")\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = data.drop(columns=[\"Location\", \"RainTomorrow\"])\n",
    "y = data[\"RainTomorrow\"]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training set, transform the testing set\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine (SVM) Classifier:\n",
      "Before tuning hyperparameters:\n",
      "Training Accuracy: 0.8622315696258579\n",
      "Testing Accuracy: 0.8572946646003985\n",
      "\n",
      "After tuning hyperparameters:\n",
      "Training Accuracy: 0.8763117113128183\n",
      "Testing Accuracy: 0.8599955722824884\n"
     ]
    }
   ],
   "source": [
    "# Initialize SVM model\n",
    "svm_model = SVC(random_state=0)\n",
    "\n",
    "# Fit SVM model\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate SVM model before tuning\n",
    "svm_train_accuracy_before = svm_model.score(X_train_scaled, y_train)\n",
    "svm_test_accuracy_before = svm_model.score(X_test_scaled, y_test)\n",
    "\n",
    "# Print results before tuning\n",
    "print(\"Support Vector Machine (SVM) Classifier:\")\n",
    "print(\"Before tuning hyperparameters:\")\n",
    "print(\"Training Accuracy:\", svm_train_accuracy_before)\n",
    "print(\"Testing Accuracy:\", svm_test_accuracy_before)\n",
    "\n",
    "# Define a smaller search space for SVM hyperparameters\n",
    "param_grid_svm = {'C': [1, 10], 'gamma': [0.1, 'scale']}\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "grid_search_svm = GridSearchCV(SVC(random_state=0), param_grid=param_grid_svm, cv=2, n_jobs=-1)\n",
    "grid_search_svm.fit(X_train_scaled, y_train)\n",
    "svm_model_tuned = grid_search_svm.best_estimator_\n",
    "\n",
    "# Evaluate SVM model after tuning\n",
    "svm_train_accuracy_after = svm_model_tuned.score(X_train_scaled, y_train)\n",
    "svm_test_accuracy_after = svm_model_tuned.score(X_test_scaled, y_test)\n",
    "\n",
    "# Print results after tuning\n",
    "print(\"\\nAfter tuning hyperparameters:\")\n",
    "print(\"Training Accuracy:\", svm_train_accuracy_after)\n",
    "print(\"Testing Accuracy:\", svm_test_accuracy_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian networks don't typically have hyperparameters in the same sense as other machine learning models like SVM or neural networks.\n",
    "\n",
    "Instead of hyperparameter tuning, the focus in Bayesian networks is often on selecting the best structure and estimating its parameters given the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import BayesianEstimator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from CSV file\n",
    "data = pd.read_csv(\"modified_dataset.csv\")\n",
    "\n",
    "# Specify the desired sample size\n",
    "sample_size = 1000  # Adjust this value according to your requirements\n",
    "\n",
    "# Randomly sample from the dataset\n",
    "smaller_data = data.sample(n=sample_size, random_state=42)\n",
    "\n",
    "# Save the smaller dataset to a new CSV file\n",
    "smaller_data.to_csv(\"smaller_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from CSV file\n",
    "data = pd.read_csv(\"smaller_dataset.csv\")\n",
    "selected_columns = ['Humidity3pm', 'RainToday', 'MaxTemp', 'Rainfall', 'RainTomorrow']\n",
    "data_subset = data[selected_columns]\n",
    "\n",
    "# Define features and target variable\n",
    "X = data_subset[['Humidity3pm', 'RainToday', 'MaxTemp', 'Rainfall']]\n",
    "y = data_subset['RainTomorrow']\n",
    "\n",
    "selected_columns = ['Humidity3pm', 'RainToday', 'MaxTemp', 'Rainfall']\n",
    "data_subset = data_subset[selected_columns]\n",
    "\n",
    "# Print the variable names\n",
    "variable_names = X.columns.tolist()\n",
    "print(\"Variable names used and passed to the model:\", variable_names)\n",
    "print(\"Columns in data: \" + str(list(data_subset.columns)))\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the structure of the simplified Bayesian Network\n",
    "model = BayesianNetwork([\n",
    "    ('Humidity3pm', 'RainTomorrow'),\n",
    "    ('RainToday', 'RainTomorrow'),\n",
    "    ('MaxTemp', 'RainTomorrow'),\n",
    "    ('Rainfall', 'RainTomorrow')\n",
    "])\n",
    "\n",
    "# Estimate the parameters of the model using BayesianEstimator\n",
    "model.fit(X_train, estimator=BayesianEstimator, n_jobs=-1)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (y_pred['RainTomorrow'] == y_test).mean()\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
